{"cells":[{"metadata":{},"cell_type":"markdown","source":"Notebook này cài đặt mạng học sâu bằng Pytorch cho bộ dữ liệu FashionMNIST. Ta cài đặt 2 kiến trúc: Multi-layer Perceptron là mô hình baseline và Convolutional Neural Network là mô hình cải tiến để dự đoán các class của bộ dữ liệu"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import một số module cần thiết\nimport os, sys\nimport numpy as np\nimport pandas as pd\nimport warnings, random\nwarnings.filterwarnings('ignore')\nprint(os.listdir('../input/fashionmnist'))","execution_count":1,"outputs":[{"output_type":"stream","text":"['t10k-labels-idx1-ubyte', 'train-images-idx3-ubyte', 'fashion-mnist_train.csv', 'train-labels-idx1-ubyte', 't10k-images-idx3-ubyte', 'fashion-mnist_test.csv']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Load data từ ổ đĩa bằng phương thức read_csv() của pandas."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Đọc lên tập train và test\ntrain = pd.read_csv('../input/fashionmnist/fashion-mnist_train.csv')\ntest = pd.read_csv('../input/fashionmnist/fashion-mnist_test.csv')\ntrain.shape, test.shape","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"((60000, 785), (10000, 785))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label = train.label\ntrain.drop(columns = 'label', inplace = True)\n\ntest_label = test.label\ntest.drop(columns = 'label', inplace = True)","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bước 1: Chuẩn bị dữ liệu"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import TensorDataset, Dataset, DataLoader, SubsetRandomSampler\nfrom torchvision import datasets, transforms\nimport random","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Xây dựng class kế thừa từ class Dataset, ta đặt tên là **FashionData**.\n\n* Gồm 2 phương thức: get_item( ) and len().\n* get_item( ) trả về những hình ảnh và nhãn tương ứng và len( ) trả về số lượng phần tử trong dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Viết class Dataset\nclass FashionDataset(Dataset):\n    def __init__(self, data, label, transform = None):\n        self.data = data\n        self.label = label\n  \n    def __len__(self):\n        return(len(self.data))\n\n    def __getitem__(self,idx):\n        self.x = self.data.loc[idx,:].values\n        self.y = self.label.loc[idx]\n        return(self.x, self.y)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chia dữ liệu ban đầu thành 2 tập train và validation\nindices = len(train)\nindices = [a for a in range(indices)]\nsplit = 0.20 # Tỉ lệ chia\nsplit = int(np.floor(split*len(train)))\nrandom.shuffle(indices)\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tạo Dataloader cho tập train, validation và test"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tạo các DataLoader\ntraining = FashionDataset(train, train_label, transforms.ToTensor())\ntraining_loader = DataLoader(training, batch_size=64, sampler=train_sampler)\n\nvalid_loader = DataLoader(training, batch_size=64, sampler=valid_sampler)\n\ntesting = FashionDataset(test, test_label, transforms.ToTensor())\ntesting_loader = DataLoader(testing, batch_size=64)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bước 2: Xây dựng kiến trúc mô hình\nChúng ta sẽ xây dựng kiến trúc mạng và huấn luyện nó trên tập train. Liên tục đánh giá nó trên tập validation"},{"metadata":{},"cell_type":"markdown","source":"## 2.1) Mô hình Baseline: Multi Layer Perceptron"},{"metadata":{"trusted":true},"cell_type":"code","source":"pymodel_mlp = nn.Sequential(nn.Linear(784,784),\n                        nn.ReLU(),\n                        nn.Dropout(p=0.3),\n                        nn.BatchNorm1d(784),\n                        nn.Linear(784,256),\n                        nn.ReLU(),\n                        nn.Dropout(p=0.4),\n                        nn.BatchNorm1d(256),\n                        nn.Linear(256,128),\n                        nn.ReLU(),\n                        nn.Dropout(p=0.3),\n                        nn.BatchNorm1d(128),\n                        nn.Linear(128,64),\n                        nn.ReLU(),\n                        nn.Dropout(p=0.4),\n                        nn.BatchNorm1d(64),\n                        nn.Linear(64,10),\n                        nn.LogSoftmax(dim = 1),)\n\ncriterion = nn.NLLLoss()\noptimizer = torch.optim.Adam(pymodel_mlp.parameters(), lr = 0.008)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nếu có GPU có sẵn thì sử dụng để tính toán nhanh, không thì sử dụng CPU.\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\npymodel_mlp = pymodel_mlp.to(device)\n\nepoch = 15\nvalid_score = np.inf\ntorch_valid_loss = []\ntorch_valid_acc  = []\n\nfor e in range(epoch):\n    training_loss = 0\n    valid_loss  = 0\n\n    running_loss = 0\n    pymodel_mlp.train()\n    for image, label in training_loader :\n        optimizer.zero_grad()\n        image = image.to(device)\n        label = label.to(device)\n        out = pymodel_mlp(image.float())\n        loss = criterion(out,label)\n        running_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n  \n    with torch.no_grad():\n        running_valid = 0\n        acc_valid = 0\n        pymodel_mlp.eval()\n        for image, label in valid_loader:\n            image = image.to(device)\n            label = label.to(device)\n            out = pymodel_mlp(image.float())\n            loss = criterion(out, label)\n            top_p, top_class = torch.exp(out).topk(1, dim = 1)\n            equal = top_class == label.view(top_class.shape)\n            accuracy = torch.mean(equal.type(torch.FloatTensor))\n            running_valid += loss.item()\n            acc_valid += accuracy.item()\n    \n    if running_valid < valid_score :\n        torch.save(pymodel_mlp.state_dict(), 'checkpoint.pth')\n        print('\\nError changes from {} to {}'.format(valid_score/len(valid_loader), running_valid/len(valid_loader)))\n        valid_score = running_valid\n        print('Saved model\\n')\n        \n    training_loss = running_loss/len(training_loader)\n    valid_loss    = running_valid/len(valid_loader)\n\n    torch_valid_loss.append(valid_loss)\n    torch_valid_acc.append(acc_valid/len(valid_loader))\n    print('Epoch : %s\\nTraining_error : %s\\nValid_error    : %s\\nAccuracy_valid : %s\\n------------------------------' \n          %(e+1, training_loss, valid_loss, acc_valid/len(valid_loader)))","execution_count":10,"outputs":[{"output_type":"stream","text":"\nError changes from inf to 6.771843608548033\nSaved model\n\nEpoch : 1\nTraining_error : 0.7322680272261302\nValid_error    : 6.771843608548033\nAccuracy_valid : 0.8072639627659575\n------------------------------\nEpoch : 2\nTraining_error : 0.5962818371852239\nValid_error    : 13.718641571145742\nAccuracy_valid : 0.836186835106383\n------------------------------\nEpoch : 3\nTraining_error : 0.5740795629024505\nValid_error    : 2094.3073560289563\nAccuracy_valid : 0.8265458776595744\n------------------------------\nEpoch : 4\nTraining_error : 0.5376429861783981\nValid_error    : 619.3068311193839\nAccuracy_valid : 0.84375\n------------------------------\nEpoch : 5\nTraining_error : 0.5316599046389262\nValid_error    : 188.66686529674112\nAccuracy_valid : 0.8376828457446809\n------------------------------\nEpoch : 6\nTraining_error : 0.5182517867485682\nValid_error    : 654.6007492765784\nAccuracy_valid : 0.8408410904255319\n------------------------------\nEpoch : 7\nTraining_error : 0.4947331133087476\nValid_error    : 25.543811161705154\nAccuracy_valid : 0.8538065159574468\n------------------------------\nEpoch : 8\nTraining_error : 0.4860947090983391\nValid_error    : 43.683842435479164\nAccuracy_valid : 0.8538065159574468\n------------------------------\nEpoch : 9\nTraining_error : 0.4714432741999626\nValid_error    : 12.235392327796905\nAccuracy_valid : 0.8594581117021277\n------------------------------\nEpoch : 10\nTraining_error : 0.4768270928064982\nValid_error    : 3238.389541657047\nAccuracy_valid : 0.8301196808510638\n------------------------------\nEpoch : 11\nTraining_error : 0.49624279322226844\nValid_error    : 6606.538152142091\nAccuracy_valid : 0.855967420212766\n------------------------------\nEpoch : 12\nTraining_error : 0.4866546875834465\nValid_error    : 12694.480952962282\nAccuracy_valid : 0.8415890957446809\n------------------------------\nEpoch : 13\nTraining_error : 0.473901708761851\nValid_error    : 10889.105348540272\nAccuracy_valid : 0.8551363031914894\n------------------------------\nEpoch : 14\nTraining_error : 0.4691840709646543\nValid_error    : 14499.99066169679\nAccuracy_valid : 0.856216755319149\n------------------------------\nEpoch : 15\nTraining_error : 0.45372989189624785\nValid_error    : 1399.6396518020713\nAccuracy_valid : 0.8622007978723404\n------------------------------\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 2.2) Mô hình cải tiến: Convolutional Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.nn import functional as f\nclass net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv2d_32 = nn.Conv2d(1,32,3,padding=1)\n        self.conv2d_64 = nn.Conv2d(32,64,3,padding=1)\n        self.max2d     = nn.MaxPool2d(2,2)\n        self.conv2d_128 = nn.Conv2d(64,128,3,padding=1)\n        self.conv2d_256 = nn.Conv2d(128,256,3, stride = 2,padding=1)\n        self.linear1    = nn.Linear(3*3*256, 256)\n        self.linear2    = nn.Linear(256,64)\n        self.linear3    = nn.Linear(64,10)\n        self.batch2d1     = nn.BatchNorm2d(64)\n        self.batch2d2    = nn.BatchNorm2d(256)\n        self.batch1d     = nn.BatchNorm1d(64)\n        self.drop      = nn.Dropout(p=0.3)\n        self.flat      = nn.Flatten()\n    \n    def forward(self,x):\n        x = x.view(-1,1,28,28)\n        x = f.relu(self.conv2d_32(x))\n        x = f.relu(self.conv2d_64(x))\n        x = self.batch2d1(x)\n        x = f.relu(self.max2d(x))\n        x = self.drop(x)\n        \n        x = f.relu(self.conv2d_128(x))\n        x = f.relu(self.conv2d_256(x))\n        x = self.batch2d2(x)\n        x = f.relu(self.max2d(x))\n        x = self.drop(x)\n        \n        x = self.flat(x)\n        x = f.relu(self.linear1(x))\n        x = self.drop(x)\n        x = f.relu(self.linear2(x))\n        x = self.drop(x)\n        x = self.batch1d(x)\n        x = f.log_softmax(self.linear3(x), dim=1)\n        return(x)\n\npymodel_cnn = net()\ncriterion = nn.NLLLoss()\noptimizer = torch.optim.Adam(pymodel_cnn.parameters(), lr = 0.008)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nếu có GPU có sẵn thì sử dụng để tính toán nhanh, không thì sử dụng CPU.\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\npymodel_cnn = pymodel_cnn.to(device)\nepoch = 15\nvalid_score = np.inf\ntorch_valid_loss_cnn = []\ntorch_valid_acc_cnn  = []\n\nfor e in range(epoch):\n    training_loss = 0\n    valid_loss  = 0\n\n    running_loss = 0\n    pymodel_cnn.train()\n    for image, label in training_loader :\n        optimizer.zero_grad()\n        image = image.to(device)\n        label = label.to(device)\n        out = pymodel_cnn(image.float())\n        loss = criterion(out,label)\n        running_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n  \n    with torch.no_grad():\n        running_valid = 0\n        acc_valid = 0\n        pymodel_cnn.eval()\n        for image, label in valid_loader:\n            image = image.to(device)\n            label = label.to(device)\n            out = pymodel_cnn(image.float())\n            loss = criterion(out, label)\n            top_p, top_class = torch.exp(out).topk(1, dim = 1)\n            equal = top_class == label.view(top_class.shape)\n            accuracy = torch.mean(equal.type(torch.FloatTensor))\n            running_valid += loss.item()\n            acc_valid += accuracy.item()\n    \n    if running_valid < valid_score :\n        torch.save(pymodel_cnn.state_dict(), 'checkpoint_cnn.pth')\n        print('\\nError changes from {} to {}'.format(valid_score/len(valid_loader), running_valid/len(valid_loader)))\n        valid_score = running_valid\n        print('Saved model\\n')\n\n    training_loss = running_loss/len(training_loader)\n    valid_loss    = running_valid/len(valid_loader)\n\n    torch_valid_loss_cnn.append(valid_loss)\n    torch_valid_acc_cnn.append(acc_valid/len(valid_loader))\n    print('Epoch : %s\\nTraining_error : %s\\nValid_error    : %s\\nAccuracy_valid : %s\\n------------------------------' \n          %(e+1, training_loss, valid_loss, acc_valid/len(valid_loader)))","execution_count":12,"outputs":[{"output_type":"stream","text":"\nError changes from inf to 0.38667745690079447\nSaved model\n\nEpoch : 1\nTraining_error : 0.6233714703321457\nValid_error    : 0.38667745690079447\nAccuracy_valid : 0.8584607712765957\n------------------------------\n\nError changes from 0.38667745690079447 to 0.3736149507792706\nSaved model\n\nEpoch : 2\nTraining_error : 0.4194109150568644\nValid_error    : 0.3736149507792706\nAccuracy_valid : 0.8848071808510638\n------------------------------\n\nError changes from 0.3736149507792706 to 0.26328977427267014\nSaved model\n\nEpoch : 3\nTraining_error : 0.3568503102560838\nValid_error    : 0.26328977427267014\nAccuracy_valid : 0.9043384308510638\n------------------------------\n\nError changes from 0.26328977427267014 to 0.2631223768867711\nSaved model\n\nEpoch : 4\nTraining_error : 0.3243477244079113\nValid_error    : 0.2631223768867711\nAccuracy_valid : 0.9053357712765957\n------------------------------\n\nError changes from 0.2631223768867711 to 0.2363481508131991\nSaved model\n\nEpoch : 5\nTraining_error : 0.3034750121633212\nValid_error    : 0.2363481508131991\nAccuracy_valid : 0.9125664893617021\n------------------------------\n\nError changes from 0.2363481508131991 to 0.2306091196517995\nSaved model\n\nEpoch : 6\nTraining_error : 0.28065754037102064\nValid_error    : 0.2306091196517995\nAccuracy_valid : 0.9183011968085106\n------------------------------\nEpoch : 7\nTraining_error : 0.26465895638863246\nValid_error    : 0.3283813841086119\nAccuracy_valid : 0.925033244680851\n------------------------------\nEpoch : 8\nTraining_error : 0.25064618824919066\nValid_error    : 0.24127285487632802\nAccuracy_valid : 0.9164727393617021\n------------------------------\nEpoch : 9\nTraining_error : 0.2437014038413763\nValid_error    : 0.23265667099188617\nAccuracy_valid : 0.9168882978723404\n------------------------------\n\nError changes from 0.2306091196517995 to 0.2158454569215153\nSaved model\n\nEpoch : 10\nTraining_error : 0.2319130975306034\nValid_error    : 0.2158454569215153\nAccuracy_valid : 0.9249501329787234\n------------------------------\n\nError changes from 0.2158454569215153 to 0.1985371203577899\nSaved model\n\nEpoch : 11\nTraining_error : 0.22311631587644418\nValid_error    : 0.1985371203577899\nAccuracy_valid : 0.9247839095744681\n------------------------------\nEpoch : 12\nTraining_error : 0.212976790646712\nValid_error    : 0.20512444535864793\nAccuracy_valid : 0.9290226063829787\n------------------------------\nEpoch : 13\nTraining_error : 0.20668842593332132\nValid_error    : 0.20208749937963613\nAccuracy_valid : 0.9281914893617021\n------------------------------\nEpoch : 14\nTraining_error : 0.1972627741843462\nValid_error    : 0.23839334842372448\nAccuracy_valid : 0.9307679521276596\n------------------------------\n\nError changes from 0.1985371203577899 to 0.19230669952849758\nSaved model\n\nEpoch : 15\nTraining_error : 0.1916449271986882\nValid_error    : 0.19230669952849758\nAccuracy_valid : 0.9303523936170213\n------------------------------\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Bước 3: Đánh gía kết quả mô hình trên tập test\nLoad mô hình tốt nhất trên MLP và kiểm tra nó trên tập test"},{"metadata":{"trusted":true},"cell_type":"code","source":"state = torch.load('checkpoint.pth')\npymodel_mlp.load_state_dict(state)","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch_test_loss  = []\ntorch_test_acc   = []\n\nfor e in range(1):\n    testing_loss = 0\n    running_test = 0\n    acc_test = 0\n    pymodel_mlp.eval()\n    for image, label in testing_loader:\n        image = image.to(device)\n        label = label.to(device)\n        out = pymodel_mlp(image.float())\n        loss = criterion(out, label)\n        top_p, top_class = torch.exp(out).topk(1, dim = 1)\n        equal = top_class == label.view(top_class.shape)\n        accuracy = torch.mean(equal.type(torch.FloatTensor))\n        running_test += loss.item()\n        acc_test += accuracy.item()\n    testing_loss = running_test/len(testing_loader)\n    torch_test_loss.append(testing_loss)\n    torch_test_acc.append(acc_test/len(testing_loader))\n    print('Epoch : %s\\nTesting_error : %s\\nAccuracy_test : %s\\n----------------' %(e+1, testing_loss, acc_test/len(testing_loader)))","execution_count":14,"outputs":[{"output_type":"stream","text":"Epoch : 1\nTesting_error : 13.163866264425266\nAccuracy_test : 0.8158837579617835\n----------------\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**ACC trên tập test của MLP là 81.58%**"},{"metadata":{},"cell_type":"markdown","source":"Load mô hình tốt nhất trên CNN và kiểm tra nó trên tập test"},{"metadata":{"trusted":true},"cell_type":"code","source":"state = torch.load('checkpoint_cnn.pth')\npymodel_cnn.load_state_dict(state)\n\ntorch_test_loss_cnn  = []\ntorch_test_acc_cnn   = []\n\nfor e in range(1):\n    testing_loss = 0\n    running_test = 0\n    acc_test = 0\n    pymodel_cnn.eval()\n    with torch.no_grad():\n        for image, label in testing_loader:\n            image = image.to(device)\n            label = label.to(device)\n            out = pymodel_cnn(image.float())\n            loss = criterion(out, label)\n            top_p, top_class = torch.exp(out).topk(1, dim = 1)\n            equal = top_class == label.view(top_class.shape)\n            accuracy = torch.mean(equal.type(torch.FloatTensor))\n            running_test += loss.item()\n            acc_test += accuracy.item()\n    testing_loss = running_test/len(testing_loader)\n    torch_test_loss_cnn.append(testing_loss)\n    torch_test_acc_cnn.append(acc_test/len(testing_loader))\n    print('Epoch : %s\\nTesting_error : %s\\nAccuracy_test : %s\\n----------------' %(e+1, testing_loss, acc_test/len(testing_loader)))","execution_count":15,"outputs":[{"output_type":"stream","text":"Epoch : 1\nTesting_error : 0.19408955674167652\nAccuracy_test : 0.9325238853503185\n----------------\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**ACC trên tập test của CNN là 93.25%**"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Vậy kết quả thu được từ mô hình CNN tốt hơn MLP. Vậy ta cải tiến thành công"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}